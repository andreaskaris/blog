<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>Httpbin tshark sidecar container - Andreas Karis Blog</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.1.2, mkdocs-gitbook-1.0.7">

<link rel="shortcut icon" href="../../images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="../../css/style.min.css" rel="stylesheet"> 
</head>

<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input type="text" placeholder="Type to search" />
</div> <!-- end of book-search-input -->

<nav role="navigation">
<ul class="summary">
<li>
<a href="../.." target="_blank" class="custom-link">Andreas Karis Blog</a>
</li>
<li class="divider"></li>
<li class="chapter" data-path="">
<a href="../..">Home</a>
<li class="header">Ceph</li>

<li>
<a href="../../ceph/ceph-manual-test/" class="">Ceph manual test with qemu</a>
</li>

<li class="header">Containers</li>

<li>
<a href="../../linux/cgroups/" class="">cgroups</a>
</li>

<li>
<a href="../../linux/containers/" class="">Containers in Linux</a>
</li>

<li>
<a href="../list_docker_registry_containers/" class="">List container images in registry</a>
</li>

<li>
<a href="../../linux/namespaces/" class="">namespaces</a>
</li>

<li class="header">Linux</li>

<li>
<a href="../../linux/cgroups/" class="">cgroups</a>
</li>

<li>
<a href="../../linux/containers/" class="">Containers in Linux</a>
</li>

<li>
<a href="../../linux/java-idrac-issues/" class="">Java Idrac Issues</a>
</li>

<li>
<a href="../../linux/hugepages/" class="">Hugepages</a>
</li>

<li>
<a href="../../linux/meson/" class="">meson</a>
</li>

<li>
<a href="../../linux/namespaces/" class="">namespaces</a>
</li>

<li>
<a href="../../linux/old_java_version_with_xorgs_in_container/" class="">Old Java inside a container with xorgs</a>
</li>

<li class="header">Networking</li>

<li>
<a href="../../networking/arp_and_the_neighbor_table/" class="">ARP and the Neighbor table</a>
</li>

<li>
<a href="../../networking/bpf-and-tcpdump/" class="">BPF and tcpdump</a>
</li>

<li>
<a href="../../networking/bonding_in_linux/" class="">Bonding in Linux</a>
</li>

<li>
<a href="../../networking/juniper_x520/" class="">Configure Juniper switch</a>
</li>

<li>
<a href="../../networking/haproxy-and-h2c/" class="">haproxy and HTTP/2</a>
</li>

<li>
<a href="../../networking/geneve_tunneling/" class="">Geneve tunneling</a>
</li>

<li>
<a href="../../networking/netlink/" class="">Netlink</a>
</li>

<li>
<a href="../../networking/ovn-kind/" class="">OVN kind</a>
</li>

<li>
<a href="../../networking/ovn_standalone_on_fedora31/" class="">OVN standalone on Fedora 31</a>
</li>

<li>
<a href="../../networking/ovs_recirculation/" class="">OVS packet recirculation</a>
</li>

<li>
<a href="../../networking/ovs-vxlan-tunnels-and-dscp/" class="">OVS VXLAN tunnels and DSCP</a>
</li>

<li>
<a href="../../networking/ovs_with_gdb/" class="">OVS with GDB</a>
</li>

<li>
<a href="../../networking/sctp/" class="">SCTP</a>
</li>

<li>
<a href="../../networking/wireguard/" class="">Wireguard</a>
</li>

<li class="header">OpenShift</li>

<li>
<a href="../alertmanager/" class="">AlertManager</a>
</li>

<li>
<a href="../cpu-manager-with-custom-machine-config-pool/" class="">CPU manager with custom MachineConfigPool</a>
</li>

<li>
<a href="../crio-conmon-runc/" class="">Crio vs conmon vs runc</a>
</li>

<li>
<a href="../etcd_perf/" class="">Etcd Performance tests</a>
</li>

<li>
<a href="./" class="active">Httpbin tshark sidecar container</a>
</li>

<li>
<a href="../kubernetes_cluster/" class="">Hints for installing kubernetes on Fedora</a>
</li>

<li>
<a href="../HPA/" class="">Horizontal Pod Autoscaler</a>
</li>

<li>
<a href="../how_rhcos_updates_work/" class="">How RHCOS updates work</a>
</li>

<li>
<a href="../ocp4-infra-nodes-with-machineset-without-worker-label/" class="">Infra nodes with MachineSets without worker label</a>
</li>

<li>
<a href="../ingresscontroller_router_sharding_ocp_on_osp/" class="">Ingress Controller Sharding OCP on OSP</a>
</li>

<li>
<a href="../ingress-controller-sharding-on-separate-vip/" class="">Ingress Controller Sharding on separate VIP</a>
</li>

<li>
<a href="../openshift_mirror_registry/" class="">Installing a cluster with a mirror registry</a>
</li>

<li>
<a href="../istio-1.6-on-ocp.4.x/" class="">Istio 1.6 on OpenShift 4.x</a>
</li>

<li>
<a href="../kata/" class="">kata containers and the kata operatora</a>
</li>

<li>
<a href="../kind-with-private-registry/" class="">Kind with private registry</a>
</li>

<li>
<a href="../mounting-container-image/" class="">Mount a container image</a>
</li>

<li>
<a href="../../openstack/install_openshift_on_openstack/" class="">OpenShift on OpenStack</a>
</li>

<li>
<a href="../private-registry/" class="">Private container registry</a>
</li>

<li>
<a href="../proxy-ocp-4.5/" class="">Proxy OCP 4.5</a>
</li>

<li>
<a href="../scc/" class="">Security Context Constraints (SCC)</a>
</li>

<li>
<a href="../fix-selinux-labels-coreos/" class="">SElinux labels fix</a>
</li>

<li>
<a href="../../networking/sctp/" class="">SCTP</a>
</li>

<li>
<a href="../openshift_troubleshooting_etcd_state/" class="">Troubleshooting etcd state</a>
</li>

<li>
<a href="../useful-ocp-curl/" class="">Querying the OCP 4.x upgrades info API</a>
</li>

<li>
<a href="../troubleshooting_openshift_on_openstack_worker_creation/" class="">Troubleshooting OpenShift on OpenStack worker creation</a>
</li>

<li class="header">OpenStack</li>

<li>
<a href="../../openstack/reattach_to_running_deployment/" class="">Reattach to running deployment</a>
</li>

<li>
<a href="../../openstack/using_clouds_yaml/" class="">Using clouds.yaml</a>
</li>

<li class="header">OperatorSDK</li>

<li>
<a href="../../operator-sdk/operator-sdk-reconciliation/" class="">Controller Reconciliation</a>
</li>

<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">
<div id="book-search-results">
<div class="search-noresults">

<section class="normal markdown-section">



<h1 id="alertmanager">AlertManager</h1>
<h2 id="configuring-alertmanager-with-webhooks-and-httpbin-container-with-tshark-sidecar-as-a-consumer">Configuring Alertmanager with webhooks and httpbin container with tshark sidecar as a consumer</h2>
<h3 id="summary">Summary</h3>
<p>The following describe a setup on OCP 3.11 with:
* a container running httpbin and a sidecar running tshark and filtering for incoming http requests and logging them
* configuration of Alertmanager so that it sends alerts via webhook to httpbin
* loading cluster with high number of pods
* analyzing generated alarms</p>
<h3 id="prerequisites">Prerequisites</h3>
<p>Make sure that ocntainers can run as any uid:</p>
<pre><code># oc adm policy add-scc-to-user anyuid -z default
scc &quot;anyuid&quot; added to: [&quot;system:serviceaccount:default:default&quot;]
</code></pre>

<h3 id="openshift-httpbin-with-tshark-sidecar">OpenShift httpbin with tshark sidecar</h3>
<p>The following allows us to see any incoming requests to httpbin but to filter out httpbin's answers.</p>
<p>Prerequisites:</p>
<pre><code># oc adm policy add-scc-to-user anyuid -z default
scc &quot;anyuid&quot; added to: [&quot;system:serviceaccount:default:default&quot;]
</code></pre>

<p>Create file <code>httpbin.yaml</code>:</p>
<pre><code>apiVersion: route.openshift.io/v1
kind: Route
metadata:
  labels:
    app: httpbin-deploymentconfig
  name: httpbin-service
spec:
  host: httpbin.apps.akaris2.lab.pnq2.cee.redhat.com
  port:
    targetPort: 80
  to:
    kind: Service
    name: httpbin-service
    weight: 100
  wildcardPolicy: None
---
apiVersion: v1
kind: Service
metadata:
  name: httpbin-service
  labels:
    app: httpbin-deploymentconfig
spec:
  selector:
    app: httpbin-pod
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
---
apiVersion: v1
kind: DeploymentConfig
metadata:
  name: httpbin-deploymentconfig
  labels:
    app: httpbin-deploymentconfig
spec:
  replicas: 1
  selector:
    app: httpbin-pod
  template:
    metadata:
      labels:
        app: httpbin-pod
    spec:
      containers:
      - name: tshark
        image: danielguerra/alpine-tshark 
        command:
          - &quot;tshark&quot; 
          - &quot;-i&quot; 
          - &quot;eth0&quot; 
          - &quot;-Y&quot; 
          - &quot;http&quot; 
          - &quot;-V&quot;  
          - &quot;dst&quot; 
          - &quot;port&quot;
          - &quot;80&quot;
      - name: httpbin
        image: kennethreitz/httpbin
        imagePullPolicy: Always
        command:
        - &quot;gunicorn&quot;
        - &quot;-b&quot;
        - &quot;0.0.0.0:80&quot;
        - &quot;httpbin:app&quot;
        - &quot;-k&quot;
        - &quot;gevent&quot;
        - &quot;--capture-output&quot;
        - &quot;--error-logfile&quot;
        - &quot;-&quot;
        - &quot;--access-logfile&quot;
        - &quot;-&quot;
        - &quot;--access-logformat&quot;
        - &quot;'%(h)s %(t)s %(r)s %(s)s Host: %({Host}i)s} Header-i: %({Header}i)s Header-o: %({Header}o)s'&quot;
</code></pre>

<p>Apply config:</p>
<pre><code>oc apply -f httpbin.yaml 
</code></pre>

<p>Get the pod name and loolk at the pod's logs for container <code>tshark</code>:</p>
<pre><code>[root@master-0 ~]# oc get pods -l app=httpbin-pod
NAME                               READY     STATUS    RESTARTS   AGE
httpbin-deploymentconfig-8-tgmvn   2/2       Running   0          3m
[root@master-0 ~]# oc logs httpbin-deploymentconfig-8-tgmvn -c tshark  -f
Capturing on 'eth0'
Frame 4: 535 bytes on wire (4280 bits), 535 bytes captured (4280 bits) on interface 0
    Interface id: 0 (eth0)
        Interface name: eth0
    Encapsulation type: Ethernet (1)
    Arrival Time: Mar 11, 2020 12:17:13.290037158 UTC
    [Time shift for this packet: 0.000000000 seconds]
    Epoch Time: 1583929033.290037158 seconds
    [Time delta from previous captured frame: 0.000002253 seconds]
    [Time delta from previous displayed frame: 0.000000000 seconds]
    [Time since reference or first frame: 36.739477011 seconds]
    Frame Number: 4
    Frame Length: 535 bytes (4280 bits)
    Capture Length: 535 bytes (4280 bits)
    [Frame is marked: False]
    [Frame is ignored: False]
    [Protocols in frame: eth:ethertype:ip:tcp:http:urlencoded-form]
Ethernet II, Src: 7a:9c:fa:d2:07:d8 (7a:9c:fa:d2:07:d8), Dst: 0a:58:0a:80:00:0c (0a:58:0a:80:00:0c)
    Destination: 0a:58:0a:80:00:0c (0a:58:0a:80:00:0c)
        Address: 0a:58:0a:80:00:0c (0a:58:0a:80:00:0c)
        .... ..1. .... .... .... .... = LG bit: Locally administered address (this is NOT the factory default)
        .... ...0 .... .... .... .... = IG bit: Individual address (unicast)
    Source: 7a:9c:fa:d2:07:d8 (7a:9c:fa:d2:07:d8)
        Address: 7a:9c:fa:d2:07:d8 (7a:9c:fa:d2:07:d8)
        .... ..1. .... .... .... .... = LG bit: Locally administered address (this is NOT the factory default)
        .... ...0 .... .... .... .... = IG bit: Individual address (unicast)
    Type: IPv4 (0x0800)
Internet Protocol Version 4, Src: 10.130.0.1, Dst: 10.128.0.12
    0100 .... = Version: 4
    .... 0101 = Header Length: 20 bytes (5)
    Differentiated Services Field: 0x00 (DSCP: CS0, ECN: Not-ECT)
        0000 00.. = Differentiated Services Codepoint: Default (0)
        .... ..00 = Explicit Congestion Notification: Not ECN-Capable Transport (0)
    Total Length: 521
    Identification: 0xdfdf (57311)
    Flags: 0x02 (Don't Fragment)
        0... .... = Reserved bit: Not set
        .1.. .... = Don't fragment: Set
        ..0. .... = More fragments: Not set
    Fragment offset: 0
    Time to live: 64
    Protocol: TCP (6)
    Header checksum: 0x4401 [validation disabled]
    [Header checksum status: Unverified]
    Source: 10.130.0.1
    Destination: 10.128.0.12
Transmission Control Protocol, Src Port: 38288, Dst Port: 80, Seq: 1, Ack: 1, Len: 469
    Source Port: 38288
    Destination Port: 80
    [Stream index: 1]
    [TCP Segment Len: 469]
    Sequence number: 1    (relative sequence number)
    [Next sequence number: 470    (relative sequence number)]
    Acknowledgment number: 1    (relative ack number)
    1000 .... = Header Length: 32 bytes (8)
    Flags: 0x018 (PSH, ACK)
        000. .... .... = Reserved: Not set
        ...0 .... .... = Nonce: Not set
        .... 0... .... = Congestion Window Reduced (CWR): Not set
        .... .0.. .... = ECN-Echo: Not set
        .... ..0. .... = Urgent: Not set
        .... ...1 .... = Acknowledgment: Set
        .... .... 1... = Push: Set
        .... .... .0.. = Reset: Not set
        .... .... ..0. = Syn: Not set
        .... .... ...0 = Fin: Not set
        [TCP Flags: ·······AP···]
    Window size value: 221
    [Calculated window size: 28288]
    [Window size scaling factor: 128]
    Checksum: 0xd9c6 [unverified]
    [Checksum Status: Unverified]
    Urgent pointer: 0
    Options: (12 bytes), No-Operation (NOP), No-Operation (NOP), Timestamps
        TCP Option - No-Operation (NOP)
            Kind: No-Operation (1)
        TCP Option - No-Operation (NOP)
            Kind: No-Operation (1)
        TCP Option - Timestamps: TSval 44637623, TSecr 44644920
            Kind: Time Stamp Option (8)
            Length: 10
            Timestamp value: 44637623
            Timestamp echo reply: 44644920
    [SEQ/ACK analysis]
        [iRTT: 0.001410475 seconds]
        [Bytes in flight: 470]
        [Bytes sent since last PSH flag: 469]
    TCP payload (469 bytes)
Hypertext Transfer Protocol
    POST /post HTTP/1.1\r\n
        [Expert Info (Chat/Sequence): POST /post HTTP/1.1\r\n]
            [POST /post HTTP/1.1\r\n]
            [Severity level: Chat]
            [Group: Sequence]
        Request Method: POST
        Request URI: /post
        Request Version: HTTP/1.1
</code></pre>

<h3 id="configuring-alertmanager-to-send-webhooks-to-httpbin-pod">Configuring Alertmanager to send webhooks to httpbin pod</h3>
<p>Prerequisites:
* https://docs.openshift.com/container-platform/3.11/install_config/prometheus_cluster_monitoring.html</p>
<p>In the following, replace <code>myuser</code> with the user who shall log into alertmanager:</p>
<pre><code>$ oc adm policy add-cluster-role-to-user cluster-monitoring-view myuser
cluster role &quot;cluster-monitoring-view&quot; added: &quot;myuser&quot;
</code></pre>

<p>We can use the above to tell alertmanager to use httpbin as its web hook:</p>
<pre><code>$ oc get routes -n openshift-monitoring
NAME                HOST/PORT                                                                     PATH      SERVICES            PORT      TERMINATION   WILDCARD
alertmanager-main   alertmanager-main-openshift-monitoring.apps.akaris2.lab.pnq2.cee.redhat.com             alertmanager-main   web       reencrypt     None
grafana             grafana-openshift-monitoring.apps.akaris2.lab.pnq2.cee.redhat.com                       grafana             https     reencrypt     None
prometheus-k8s      prometheus-k8s-openshift-monitoring.apps.akaris2.lab.pnq2.cee.redhat.com                prometheus-k8s      web       reencrypt     None
</code></pre>

<p>Now, access:</p>
<pre><code>https://alertmanager-main-openshift-monitoring.apps.akaris2.lab.pnq2.cee.redhat.com
</code></pre>

<p>The status page will show the current alertmanager configuration.</p>
<p>The following Red Hat knowledge base solution shows how to update the alertmanager config: https://access.redhat.com/solutions/3804781</p>
<p>Create file: <code>~/group_vars/OSEv3.yml</code>:</p>
<pre><code>openshift_cluster_monitoring_operator_alertmanager_config: |+
  global:
    resolve_timeout: 2m
  route:
    group_wait: 5s
    group_interval: 10s
    repeat_interval: 20s
    receiver: default
    routes:
    - match:
        alertname: DeadMansSwitch
      repeat_interval: 30s
      receiver: deadmansswitch
    - match:
        alertname: DeadMansSwitch
      repeat_interval: 30s
      receiver: wh
    - match:
        alertname: '*'
      repeat_interval: 2m
      receiver: wh
    - match:
        severity: critical
      receiver: wh
    - match:
        severity: warning
      receiver: wh
    - match:
        alertname: KubeAPILatencyHigh
      receiver: wh
  receivers:
  - name: default
  - name: deadmansswitch
  - name: wh
    webhook_configs:
      - url: &quot;http://httpbin.apps.akaris2.lab.pnq2.cee.redhat.com/anything&quot;
</code></pre>

<p>And run:</p>
<pre><code>ansible-playbook -i hosts openshift-ansible/playbooks/openshift-monitoring/config.yml -e=&quot;openshift_cluster_monitoring_operator_install=true&quot;
</code></pre>

<p>Verify:</p>
<pre><code>$ oc get secret -n openshift-monitoring alertmanager-main -o yaml | awk '/alertmanager.yaml:/ {print $NF}' | base64 -d
global:
  resolve_timeout: 2m
route:
  group_wait: 5s
  group_interval: 10s
  repeat_interval: 20s
  receiver: default
  routes:
  - match:
      alertname: DeadMansSwitch
    repeat_interval: 30s
    receiver: deadmansswitch
  - match:
      alertname: DeadMansSwitch
    repeat_interval: 30s
    receiver: wh
  - match:
      alertname: '*'
    repeat_interval: 2m
    receiver: wh
  - match:
      severity: critical
    receiver: wh
  - match:
      severity: warning
    receiver: wh
  - match:
      alertname: KubeAPILatencyHigh
    receiver: wh
receivers:
- name: default
- name: deadmansswitch
- name: wh
  webhook_configs:
    - url: &quot;http://httpbin.apps.akaris2.lab.pnq2.cee.redhat.com/anything&quot;
</code></pre>

<p>Restart pods:</p>
<pre><code>$ oc delete pods --selector=app=alertmanager -n openshift-monitoring
pod &quot;alertmanager-main-0&quot; deleted
pod &quot;alertmanager-main-1&quot; deleted
pod &quot;alertmanager-main-2&quot; deleted
</code></pre>

<p>And check in the web interface of alertmanager to make sure that the new configuration shows up.</p>
<h3 id="loading-the-cluster">Loading the cluster</h3>
<p>An easy way to generate an alert in a small lab is to trigger alert <code>KubeletTooManyPods</code>. Go to prometheus and check its configuration:</p>
<pre><code>alert: KubeletTooManyPods
expr: kubelet_running_pod_count{job=&quot;kubelet&quot;}
  &gt; 250 * 0.9
for: 15m
labels:
  severity: warning
annotations:
  message: Kubelet {{ $labels.instance }} is running {{ $value }} Pods, close to the
    limit of 250.
</code></pre>

<p>Then, create the following busybox deployment with a number of pods that exceeds this number, e.g.:
<code>busybox.yaml</code>:</p>
<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: busybox-deployment
  labels:
    app: busybox-deployment
spec:
  replicas: 500
  selector:
    matchLabels:
      app: busybox-pod
  template:
    metadata:
      labels:
        app: busybox-pod
    spec:
      containers:
      - name: busybox
        image: busybox
        command:
          - sleep
          - infinity
        imagePullPolicy: IfNotPresent
</code></pre>

<pre><code>oc apply -f busybox.yaml
</code></pre>

<p>The cluster will need some time to create those pods and it'll take 15 minutes for the alarm to fire. So take a coffee and come back later. Once the alarm fires in prometheus, go to alertmanager and make sure that it shows there, too.</p>
<p>Among others, Alertmanager should show:</p>
<pre><code>alertname=&quot;KubeletTooManyPods&quot;
16:06:32, 2020-03-11
message:    Kubelet 10.74.176.204:10250 is running 250 Pods, close to the limit of 250.
severity=&quot;warning&quot;
service=&quot;kubelet&quot;prometheus=&quot;openshift-monitoring/k8s&quot;namespace=&quot;kube-system&quot;job=&quot;kubelet&quot;instance=&quot;10.74.176.204:10250&quot;endpoint=&quot;https-metrics&quot;
</code></pre>

<p>Now, it's time to go back to the httpbin pod.</p>
<h3 id="monitoring-incoming-webhook-reuests">Monitoring incoming webhook reuests</h3>
<p>Get the pod name:</p>
<pre><code># oc get pods | grep httpbin
httpbin-deploymentconfig-8-8crvh     2/2       Running   0          1h
</code></pre>

<p>And check the logs of the tshark container which will show a verbose packet capture of HTTP with a destination port of 80 (so we are not capturing the response):</p>
<pre><code># oc logs httpbin-deploymentconfig-8-8crvh -c tshark | tail -n 400
(...)
Frame 1708: 5220 bytes on wire (41760 bits), 5220 bytes captured (41760 bits) on interface 0
    Interface id: 0 (eth0)
        Interface name: eth0
(...)
Ethernet II, Src: ... (...), Dst: ... (...)
(...)
Internet Protocol Version 4, Src: ..., Dst: ...
(...)
Transmission Control Protocol, Src Port: 41606, Dst Port: 80, Seq: 1, Ack: 1, Len: 5154
(...)
Hypertext Transfer Protocol
    POST /anything HTTP/1.1\r\n
        [Expert Info (Chat/Sequence): POST /anything HTTP/1.1\r\n]
            [POST /anything HTTP/1.1\r\n]
            [Severity level: Chat]
            [Group: Sequence]
        Request Method: POST
        Request URI: /anything
        Request Version: HTTP/1.1
    User-Agent: Alertmanager/0.15.2\r\n
    Content-Length: 4743\r\n
        [Content length: 4743]
    Content-Type: application/json\r\n
(...)
JavaScript Object Notation: application/json
    Object
        Member Key: receiver
            String value: wh
            Key: receiver
        Member Key: status
            String value: firing
            Key: status
        Member Key: alerts
            Array
                Object
                    Member Key: status
                        String value: firing
                        Key: status
                    Member Key: labels
                        Object
                            Member Key: alertname
                                String value: KubeDaemonSetRolloutStuck
                                Key: alertname
                            Member Key: cluster
                                String value: openshift.akaris2.lab.pnq2.cee.redhat.com
                                Key: cluster
                            Member Key: daemonset
                                String value: node-exporter
                                Key: daemonset
                            Member Key: endpoint
                                String value: https-main
                                Key: endpoint
                            Member Key: instance
                                String value: ...:8443
                                Key: instance
                            Member Key: job
                                String value: kube-state-metrics
                                Key: job
                            Member Key: namespace
                                String value: openshift-monitoring
                                Key: namespace
                            Member Key: pod
                                String value: kube-state-metrics-6f4c658bcc-v57b6
                                Key: pod
                            Member Key: prometheus
                                String value: openshift-monitoring/k8s
                                Key: prometheus
                            Member Key: service
                                String value: kube-state-metrics
                                Key: service
                            Member Key: severity
                                String value: critical
                                Key: severity
                        Key: labels
                    Member Key: annotations
                        Object
                            Member Key: message
                                String value: Only 66.66666666666666% of desired pods scheduled and ready for daemon set openshift-monitoring/node-exporter
                                Key: message
                        Key: annotations
                    Member Key: startsAt
                        String value: 2020-03-11T16:07:40.59085788Z
                        Key: startsAt
                    Member Key: endsAt
                        String value: 0001-01-01T00:00:00Z
                        Key: endsAt
                    Member Key: generatorURL
                        String value [truncated]: https://prometheus-k8s-openshift-monitoring.apps.akaris2.lab.pnq2.cee.redhat.com/graph?g0.expr=kube_daemonset_status_number_ready%7Bjob%3D%22kube-state-metrics%22%2Cnamespace%3D~%22%28openshift-.%2A%7Ckube-.%2A%7C
                        Key: generatorURL
                Object
                    Member Key: status
                        String value: firing
                        Key: status
                    Member Key: labels
                        Object
                            Member Key: alertname
                                String value: KubeDaemonSetRolloutStuck
                                Key: alertname
                            Member Key: cluster
                                String value: openshift.akaris2.lab.pnq2.cee.redhat.com
                                Key: cluster
                            Member Key: daemonset
                                String value: ovs
                                Key: daemonset
                            Member Key: endpoint
                                String value: https-main
                                Key: endpoint
                            Member Key: instance
                                String value: ...:8443
                                Key: instance
                            Member Key: job
                                String value: kube-state-metrics
                                Key: job
                            Member Key: namespace
                                String value: openshift-sdn
                                Key: namespace
                            Member Key: pod
                                String value: kube-state-metrics-6f4c658bcc-v57b6
                                Key: pod
                            Member Key: prometheus
                                String value: openshift-monitoring/k8s
                                Key: prometheus
                            Member Key: service
                                String value: kube-state-metrics
                                Key: service
                            Member Key: severity
                                String value: critical
                                Key: severity
                        Key: labels
                    Member Key: annotations
                        Object
                            Member Key: message
                                String value: Only 66.66666666666666% of desired pods scheduled and ready for daemon set openshift-sdn/ovs
                                Key: message
                        Key: annotations
                    Member Key: startsAt
                        String value: 2020-03-11T16:07:40.59085788Z
                        Key: startsAt
                    Member Key: endsAt
                        String value: 0001-01-01T00:00:00Z
                        Key: endsAt
                    Member Key: generatorURL
                        String value [truncated]: https://prometheus-k8s-openshift-monitoring.apps.akaris2.lab.pnq2.cee.redhat.com/graph?g0.expr=kube_daemonset_status_number_ready%7Bjob%3D%22kube-state-metrics%22%2Cnamespace%3D~%22%28openshift-.%2A%7Ckube-.%2A%7C
                        Key: generatorURL
                Object
                    Member Key: status
                        String value: firing
                        Key: status
                    Member Key: labels
                        Object
                            Member Key: alertname
                                String value: KubeDaemonSetRolloutStuck
                                Key: alertname
                            Member Key: cluster
                                String value: openshift.akaris2.lab.pnq2.cee.redhat.com
                                Key: cluster
                            Member Key: daemonset
                                String value: sdn
                                Key: daemonset
                            Member Key: endpoint
                                String value: https-main
                                Key: endpoint
                            Member Key: instance
                                String value: ...:8443
                                Key: instance
                            Member Key: job
                                String value: kube-state-metrics
                                Key: job
                            Member Key: namespace
                                String value: openshift-sdn
                                Key: namespace
                            Member Key: pod
                                String value: kube-state-metrics-6f4c658bcc-v57b6
                                Key: pod
                            Member Key: prometheus
                                String value: openshift-monitoring/k8s
                                Key: prometheus
                            Member Key: service
                                String value: kube-state-metrics
                                Key: service
                            Member Key: severity
                                String value: critical
                                Key: severity
                        Key: labels
                    Member Key: annotations
                        Object
                            Member Key: message
                                String value: Only 66.66666666666666% of desired pods scheduled and ready for daemon set openshift-sdn/sdn
                                Key: message
                        Key: annotations
                    Member Key: startsAt
                        String value: 2020-03-11T16:07:40.59085788Z
                        Key: startsAt
                    Member Key: endsAt
                        String value: 0001-01-01T00:00:00Z
                        Key: endsAt
                    Member Key: generatorURL
                        String value [truncated]: https://prometheus-k8s-openshift-monitoring.apps.akaris2.lab.pnq2.cee.redhat.com/graph?g0.expr=kube_daemonset_status_number_ready%7Bjob%3D%22kube-state-metrics%22%2Cnamespace%3D~%22%28openshift-.%2A%7Ckube-.%2A%7C
                        Key: generatorURL
                Object
                    Member Key: status
                        String value: firing
                        Key: status
                    Member Key: labels
                        Object
                            Member Key: alertname
                                String value: KubeDaemonSetRolloutStuck
                                Key: alertname
                            Member Key: cluster
                                String value: openshift.akaris2.lab.pnq2.cee.redhat.com
                                Key: cluster
                            Member Key: daemonset
                                String value: sync
                                Key: daemonset
                            Member Key: endpoint
                                String value: https-main
                                Key: endpoint
                            Member Key: instance
                                String value: ...:8443
                                Key: instance
                            Member Key: job
                                String value: kube-state-metrics
                                Key: job
                            Member Key: namespace
                                String value: openshift-node
                                Key: namespace
                            Member Key: pod
                                String value: kube-state-metrics-6f4c658bcc-v57b6
                                Key: pod
                            Member Key: prometheus
                                String value: openshift-monitoring/k8s
                                Key: prometheus
                            Member Key: service
                                String value: kube-state-metrics
                                Key: service
                            Member Key: severity
                                String value: critical
                                Key: severity
                        Key: labels
                    Member Key: annotations
                        Object
                            Member Key: message
                                String value: Only 66.66666666666666% of desired pods scheduled and ready for daemon set openshift-node/sync
                                Key: message
                        Key: annotations
                    Member Key: startsAt
                        String value: 2020-03-11T16:07:40.59085788Z
                        Key: startsAt
                    Member Key: endsAt
                        String value: 0001-01-01T00:00:00Z
                        Key: endsAt
                    Member Key: generatorURL
                        String value [truncated]: https://prometheus-k8s-openshift-monitoring.apps.akaris2.lab.pnq2.cee.redhat.com/graph?g0.expr=kube_daemonset_status_number_ready%7Bjob%3D%22kube-state-metrics%22%2Cnamespace%3D~%22%28openshift-.%2A%7Ckube-.%2A%7C
                        Key: generatorURL
            Key: alerts
        Member Key: groupLabels
            Object
            Key: groupLabels
        Member Key: commonLabels
            Object
                Member Key: alertname
                    String value: KubeDaemonSetRolloutStuck
                    Key: alertname
                Member Key: cluster
                    String value: openshift.akaris2.lab.pnq2.cee.redhat.com
                    Key: cluster
                Member Key: endpoint
                    String value: https-main
                    Key: endpoint
                Member Key: instance
                    String value: ...:8443
                    Key: instance
                Member Key: job
                    String value: kube-state-metrics
                    Key: job
                Member Key: pod
                    String value: kube-state-metrics-6f4c658bcc-v57b6
                    Key: pod
                Member Key: prometheus
                    String value: openshift-monitoring/k8s
                    Key: prometheus
                Member Key: service
                    String value: kube-state-metrics
                    Key: service
                Member Key: severity
                    String value: critical
                    Key: severity
            Key: commonLabels
</code></pre>


</section>
</div> <!-- end of search-noresults -->
<div class="search-results">
<div class="has-results">

<h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
<ul class="search-results-list"></ul>

</div> <!-- end of has-results -->
<div class="no-results">

<h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>

</div> <!-- end of no-results -->
</div> <!-- end of search-results -->
</div> <!-- end of book-search-results -->

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<script src="../../js/main.js"></script>
<script src="../../search/main.js"></script>
<script src="../../js/gitbook.min.js"></script>
<script src="../../js/theme.min.js"></script>
</body>
</html>